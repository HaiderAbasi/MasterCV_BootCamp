{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMeciuW0i8ol1ewTGLPYtn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"RDk6Knbjj1YB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJkvzOhyjzDk"},"outputs":[],"source":["import cv2\n","import os\n","import numpy as np\n","import time\n","\n","from src.utilities import imshow,putText,Gui,build_montages,download_missing_recog_data,download_missing_training_data\n","from src.c__Advanced.Object_detection.a_HaarCascades.a_detect_haarCascade import Cascade_Detector\n","recog_dir = os.path.dirname(__file__)"]},{"cell_type":"markdown","source":["### class FaceRecognizer"],"metadata":{"id":"3xJShdw-j-SF"}},{"cell_type":"code","source":["class FaceRecognizer:\n","\n","    def __init__(self, algorithm_type= \"LBPH\"):\n","        download_missing_recog_data(recog_dir)\n","        self.algorithm_type = algorithm_type\n","        if algorithm_type == \"Eigenfaces\":\n","            self.model = cv2.face.EigenFaceRecognizer_create()\n","        elif algorithm_type == \"Fisherfaces\":\n","            self.model = cv2.face.FisherFaceRecognizer_create()\n","        elif algorithm_type == \"LBPH\":\n","            # cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=8, grid_x=8, grid_y=8, threshold=DBL_MAX)\n","            self.model = cv2.face.LBPHFaceRecognizer_create()\n","\n","        self.labels = []\n","        self.detector = Cascade_Detector()\n","\n","        self.img_s = 100\n","\n","        self.debug = False\n","\n","        # load the landmark predictor\n","        self.landmark_predictor = cv2.face.createFacemarkLBF()\n","        self.landmark_predictor.loadModel(r\"src\\c__Advanced\\Object_recognition\\recog_data\\models\\lbfmodel.yaml\")\n","\n","    def train(self, train_dir):\n","\n","        if train_dir==\"\":\n","            print(f\"\\n[Error] Empty Train Directory = {train_dir}/n Recheck please!\")\n","            return\n","        else:\n","            print(f\"\\n[Status] Training {self.algorithm_type} on training recog_dataset at {train_dir}.\\n\")\n","\n","        images = []\n","        labels = []\n","\n","        label_list = []  # a list to store unique label names\n","\n","        for label in os.listdir(train_dir):\n","            label_dir = os.path.join(train_dir, label)\n","            self.labels.append(label)\n","            for image_name in os.listdir(label_dir):\n","                image_path = os.path.join(label_dir, image_name)\n","                gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","\n","                bboxes = self.detector.detect(gray)\n","                if len(bboxes)>0:\n","                    x,y,w,h = bboxes[0]\n","                    face = gray[y:y+h,x:x+w]\n","                    face_resized = cv2.resize(face,(self.img_s,self.img_s))\n","                    images.append(face_resized)\n","                    if label not in label_list:\n","                        label_list.append(label)\n","                    labels.append(label_list.index(label)) # Adding index of each image label to labels\n","                    if self.debug:\n","                        cv2.imshow(\"Train Image\",face_resized)\n","                        cv2.waitKey(1)\n","\n","        self.model.train(images, np.array(labels))\n","\n","    @staticmethod\n","    def align_face(face,landmarks):\n","        # Calculate eye centers\n","        left_eye = landmarks[0][36:42].mean(axis=0)\n","        right_eye = landmarks[0][42:48].mean(axis=0)\n","\n","        # Calculate angle between eyes and horizontal axis\n","        dY = right_eye[1] - left_eye[1]\n","        dX = right_eye[0] - left_eye[0]\n","        angle = np.degrees(np.arctan2(dY, dX))\n","\n","        # Rotate image\n","        (h, w) = face.shape[:2]\n","        center = (w // 2, h // 2)\n","        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","        face_aligned = cv2.warpAffine(face, M, (w, h), flags=cv2.INTER_CUBIC)\n","        return face_aligned\n","\n","    def predict(self, test_image):\n","\n","        gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n","        bboxes = self.detector.detect(gray_image)\n","        label = -1\n","        confidence = 0.0\n","        if len(bboxes)>0:\n","            x,y,w,h = bboxes[0]\n","            gray_image = gray_image[y:y+h,x:x+w]\n","\n","            gray_image = cv2.resize(gray_image,(self.img_s,self.img_s))\n","\n","            label, confidence = self.model.predict(gray_image)\n","        return label,confidence\n","\n","    # New: function to predict the identity of all people in an image\n","    def predict_multi(self, test_image, display_faces=False):\n","        orig_img = test_image.copy()\n","        gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n","        bboxes = self.detector.detect(gray_image)\n","        labels = []\n","        confidences = []\n","        if len(bboxes)>0:\n","            # perform face alignment\n","            _, landmarks = self.landmark_predictor.fit(orig_img, bboxes)\n","\n","            for i,bbox in enumerate(bboxes):\n","                x,y,w,h = bbox\n","                face = gray_image[y:y+h,x:x+w]\n","                #face_aligned = cv2.face.createFacemarkKazemi(orig_img, landmarks[i])\n","                face_aligned = self.align_face(face,landmarks[i])\n","                face = cv2.resize(face_aligned,(self.img_s,self.img_s))\n","                label, confidence = self.model.predict(face)\n","                labels.append(label)\n","                confidences.append(confidence)\n","                if display_faces:\n","                    # New: draw rectangle around detected face\n","                    cv2.rectangle(test_image, (x, y), (x + w, y + h), (0, 165, 255), 2)\n","                    # New: set text size proportional to the width of the bounding box\n","                    font_scale = 0.7 * w / 100\n","                    # New: display label and confidence score\n","                    text = f\"{self.labels[label]} ({confidence:.2f})\"\n","                    cv2.putText(test_image, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 165, 255), 2)\n","\n","        return labels, confidences\n","\n","\n","    def identify(self, test_image):\n","        gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n","        bboxes = self.detector.detect(gray_image)\n","        if len(bboxes)>0:\n","            x,y,w,h = bboxes[0]\n","            gray_image = gray_image[y:y+h,x:x+w]\n","\n","            gray_image = cv2.resize(gray_image,(self.img_s,self.img_s))\n","            if self.debug:\n","                cv2.imshow(\"Train Image\",gray_image)\n","                cv2.waitKey(1)\n","            label, confidence = self.model.predict(gray_image)\n","            label_text = f\"Label: {self.labels[label]}\"\n","\n","            putText(test_image, label_text, (10, 20),color = (0,0,0))\n","            cv2.rectangle(test_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","            return test_image, self.labels[label]\n","        else:\n","            return test_image,\"Unknown\""],"metadata":{"id":"aUtY9uADkNVE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def demo()"],"metadata":{"id":"0yTEbw2EkUZC"}},{"cell_type":"code","source":["def demo():\n","    #================================TRAINING=====================================\n","    # Set the path to the training directory\n","    train_dir = r\"src\\c__Advanced\\Object_recognition\\recog_data\\training\\cv\\Biilionaires\"\n","\n","    # Create a FaceRecognizer object\n","    face_recognizer = FaceRecognizer()\n","\n","    # Train the FaceRecognizer object\n","    train_recognizer = True\n","    if train_recognizer:\n","        face_recognizer.train(train_dir)\n","\n","    #================================IDENTIFICATIOn=====================================\n","    # Set the path to the test directory\n","    test_dir = r\"src\\c__Advanced\\Object_recognition\\recog_data\\test\\cv\"\n","\n","    # Initialize empty lists for storing images and titles\n","    images = []\n","    titles = []\n","\n","    print(f\"\\n[Status] Testing {face_recognizer.algorithm_type} on test recog_dataset at {test_dir}.\\n\")\n","    # Loop over all files in the directory\n","    for file_name in os.listdir(test_dir):\n","        # Check if the file is an image\n","        if file_name.endswith('.jpg') or file_name.endswith('.jpeg') or file_name.endswith('.png')  or file_name.endswith('.webp'):\n","            # Construct the full path to the image\n","            file_path = os.path.join(test_dir, file_name)\n","\n","            # Load test image\n","            img = cv2.imread(file_path) # prefix the string with r (to produce a raw string)\n","\n","            # Predict the label of the test image using the FaceRecognizer object\n","            print(f\"{face_recognizer.algorithm_type} trained...\\nPredicting on test images....\")\n","            start = time.time()\n","            res_img,label = face_recognizer.identify(img)\n","            time_elapsed = time.time() - start\n","            print(f\"Time took to predict {time_elapsed}.ms\")\n","\n","            # Append the resulting image and title to the corresponding lists\n","            images.append(res_img)\n","            titles.append(label)\n","\n","    # Display the resulting images with titles as a montage\n","    montage = build_montages(images, None, None, titles, True, True)\n","    for montage_img in montage:\n","        cv2.imshow(\"Face Recognition\",montage_img)\n","    cv2.waitKey(0)"],"metadata":{"id":"my_SDm2XkY6K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conditional Execution of Functions Based on Readiness Status"],"metadata":{"id":"ElbOx3h4kdGK"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    download_missing_training_data(recog_dir)\n","    demo()"],"metadata":{"id":"ikAyUKj3kfok"},"execution_count":null,"outputs":[]}]}