{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPv4hRzGv2qMAtKBGdLSxoo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"3C2CQ-ithhRg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6scmbnqzhBGK"},"outputs":[],"source":["import cv2\n","import os\n","from src.utilities import putText"]},{"cell_type":"markdown","source":["### class Cascade_Detector"],"metadata":{"id":"a-gGYSTfhs3i"}},{"cell_type":"code","source":["class Cascade_Detector:\n","    def __init__(self,object = \"face\"):\n","        self.detector = cv2.CascadeClassifier()\n","\n","        self.category = object\n","\n","        if object == \"TrafficLight\":\n","            cascade_path = \"Data/haarcascades/haarcascade_trafficlight.xml\"\n","        elif object == \"eyes\":\n","            cascade_path = 'Data/haarcascades/haarcascade_eye_tree_eyeglasses.xml'\n","        else:\n","            cascade_path = 'Data/haarcascades/haarcascade_frontalface_alt.xml'\n","\n","        self.cascade_path = os.path.join(os.getcwd(), cascade_path) # Get the absolute path.\n","\n","        if not self.detector.load(cv2.samples.findFile(self.cascade_path)):\n","            print(f'--(!)Error loading {object} cascade')\n","            exit(0)\n","\n","    def detect(self,img,display = False):\n","        \"\"\"\n","        Detects objects in an input image using the Haar cascade classifier.\n","\n","        Args:\n","            img (numpy.ndarray): Input image.\n","            display (bool): Flag to display the detected objects in the input image. Default is False.\n","\n","        Returns:\n","            numpy.ndarray: List of bounding boxes (x, y, w, h) for detected objects in the input image.\n","        \"\"\"\n","        if len(img.shape) == 3 and img.shape[2] ==3:\n","            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        else:\n","            gray = img\n","\n","        # scaleFactor: How much image size is reduced at each image scale default : 1.1 (10%)\n","        # minNeighbors: How many neighbors each candidate rectangle should have to retain it.\n","        # minSize: Object size lower limit\n","        # max Size: Object size upper limit\n","        bboxes = self.detector.detectMultiScale(gray)\n","\n","        if display and len(bboxes)!=0:\n","            for bbox in bboxes:\n","                x,y,w,h = bbox\n","\n","                # Displaying the label\n","                putText(img,self.category,(x,y-20),bbox_size=(w,h))\n","                # Drawing the bbox around the detected object\n","                cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n","\n","        return bboxes"],"metadata":{"id":"P5_j25BLh0Mz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def main()"],"metadata":{"id":"KtuTDfzoh34I"}},{"cell_type":"code","source":["def main():\n","    hc_detector = Cascade_Detector(\"TrafficLight\")\n","    vid_path = \"data/city.mp4\"\n","    #-- 2. Read the video stream\n","    cap = cv2.VideoCapture(vid_path)\n","    if not cap.isOpened:\n","        print('--(!)Error opening video capture')\n","        exit(0)\n","\n","    cv2.namedWindow(\"TrafficLight-detection_HC\",cv2.WINDOW_NORMAL)\n","    while True:\n","        ret, frame = cap.read()\n","\n","        if frame is None:\n","            print('--(!) No captured frame -- Break!')\n","            break\n","\n","        # [Task]: Detect object [Traffic Light] in frame using Haar Cascade\n","        hc_detector.detect(frame,True)\n","\n","        cv2.imshow(\"TrafficLight-detection_HC\",frame)\n","        if cv2.waitKey(10) == 27:\n","            break"],"metadata":{"id":"MAr-uhbNh7D1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conditional Execution of Functions Based on Readiness Status"],"metadata":{"id":"mU6ZjaQmh9-k"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"Mkn0ZbMpiBqT"},"execution_count":null,"outputs":[]}]}