{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcgXxpSYMjnbNEKjL/J+5H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"4wuD-lDxb5OS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EwEhcxxb0BK"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from src.utilities import debugger,build_montages,print_h,imshow,keep_blobs_by_mask,extract_blobs_on_pattern,get_centroid\n","\n","from loguru import logger"]},{"cell_type":"markdown","source":["### def segment_plants(image,debug=True)"],"metadata":{"id":"a--vn8ALb--M"}},{"cell_type":"code","source":["def segment_plants(image,debug=True):\n","    # Hint: Utilize segmentation class and investigate which segmentation works best for our case and Why?\n","    # Write Code here...\n","    plants_segmented = image.copy()\n","\n","\n","    return plants_segmented"],"metadata":{"id":"vvkFfq8AcC5a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def assignment(debug= True"],"metadata":{"id":"MrjysuUHcGSI"}},{"cell_type":"code","source":["def assignment(debug= True):\n","    if debug:\n","        print_h(\"[Assignment]: Segment max plants from the field\\n\")\n","    # Assignment: Cleanly segment maximum no of plants in the image provided.\n","    #\n","    #\n","    # Returns: (BGRA) 4-D image as an ouput. Where first 3 channels are just the original image (BGR)\n","    #                                                 Last channel is alpha (mask). Indicating segmented plants\n","    #\n","    # Hint  : A combination of segmentation algorithm might give a cleaner segmentation result.\n","    #\n","\n","    # Reading the image\n","    field = cv2.imread(\"Data/drone_view.png\")\n","\n","    if debug:\n","        imshow(\"field\",field)\n","\n","    # Task Function\n","    plants_segmented = segment_plants(field,debug)\n","\n","    if np.array_equal(plants_segmented,field):\n","        logger.error(\"segment_plants() needs to be coded to get the required(Segmented Plant) result.\")\n","        exit(0)\n","\n","    if debug:\n","        imshow(\"plants_segmented\",plants_segmented)\n","        cv2.waitKey(0)\n","\n","    return plants_segmented"],"metadata":{"id":"abAyVD3icJX9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### class segmentation"],"metadata":{"id":"zZVhqVrjcNgE"}},{"cell_type":"code","source":["class segmentation:\n","    def __init__(self):\n","        self.debugger = None\n","\n","    @staticmethod\n","    def thresholding(img,type = \"binary\"):\n","        if type == \"binary\":\n","            img_seg_thresh = cv2.threshold(img,150,255,cv2.THRESH_BINARY)[1]\n","        elif type == \"otsu\":\n","            T,img_seg_thresh = cv2.threshold(img,0,255,cv2.THRESH_OTSU|cv2.THRESH_BINARY)\n","            print(\"[INFO] otsu's thresholding value: {}\".format(T))\n","        elif type == \"adaptive-mean\":\n","            img_seg_thresh = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n","        elif type == 'adaptive-guass':\n","            img_seg_thresh = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n","        else:\n","            print(f\"Unknown thresholding type {type}\")\n","\n","        return img_seg_thresh"],"metadata":{"id":"AnOhubetcRL1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def segment_color(self,img,hue_l,hue_h)"],"metadata":{"id":"uz8d5TRBcUNx"}},{"cell_type":"code","source":["def segment_color(self,img,hue_l,hue_h):\n","        hls = cv2.cvtColor(img,cv2.COLOR_BGR2HLS)\n","        hue = hls[:,:,0]\n","        mask = cv2.inRange(hue,hue_l,hue_h)\n","        # Perform Closing operation to connect closely disconnected objects\n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n","        mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n","        return mask"],"metadata":{"id":"tX-CwOGAcYdU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def segment_edges(self,img,thresh_l,thresh_h,aperture)"],"metadata":{"id":"ep1hKb5vcdH6"}},{"cell_type":"code","source":["def segment_edges(self,img,thresh_l,thresh_h,aperture):\n","        if len(img.shape)>2:\n","            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","        else:\n","            gray = img\n","        mask = cv2.Canny(gray,thresh_l,thresh_h,None,aperture)\n","        return mask"],"metadata":{"id":"0MVX7rg5chFE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def segment_kmeans(img,clusters = 2, attempts=10)"],"metadata":{"id":"2pNInQKCcoAp"}},{"cell_type":"code","source":["def segment_kmeans(img,clusters = 2, attempts=10):\n","\n","        # Each channel/feature is placed in a single column\n","        twoDimage = img.reshape((-1,3))\n","\n","        twoDimage = np.float32(twoDimage)\n","\n","        # Defining the criteria for kmean algorithm\n","        criteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_COUNT,10,1.0)\n","\n","        _,label, center= cv2.kmeans(twoDimage,clusters,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n","        # Kmeans- Display Clusters with seperate coloring\n","        # Output Image : Convert back to Uint8-3dShaped\n","        center = np.uint8(center)\n","        res = center[label.flatten()]\n","        result_image = res.reshape((img.shape))\n","\n","        return result_image"],"metadata":{"id":"RZqzXyq4csE5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def segment(self,img,method=\"thresholding\",type=\"binary\",tune = False)"],"metadata":{"id":"TwEKM05LcxRg"}},{"cell_type":"code","source":["def segment(self,img,method=\"thresholding\",type=\"binary\",tune = False):\n","        if method == \"thresholding\":\n","            segmented = self.thresholding(img,type)\n","        elif method == \"color\":\n","            if tune:\n","                if self.debugger == None: # initialize debugger\n","                    print(\"debugger is None \")\n","                    self.debugger = debugger(\"Control\",[\"hue_l\",\"hue_h\"],[255,255])\n","                self.debugger.update_variables() # Get updated variables\n","                hue_l,hue_h= self.debugger.debug_vars[0:2]\n","            else:\n","                hue_l= 44;hue_h = 91\n","            segmented = self.segment_color(img,hue_l,hue_h)\n","        elif method == \"edges\":\n","            if tune:\n","                if self.debugger == None: #i nitialize debugger\n","                    self.debugger = debugger(\"Control (edges)\",[\"thresh_l\",\"thresh_h\",\"aperture\"],[255,255,7],[False,False,True])\n","\n","                self.debugger.update_variables() # Get updated variables\n","                thresh_l,thresh_h,aperture= self.debugger.debug_vars[0:4]\n","            else:\n","                thresh_l=185;thresh_h=255;aperture=5\n","            segmented = self.segment_edges(img,thresh_l,thresh_h,aperture)\n","        elif method ==\"kmeans\":\n","            if tune:\n","                if self.debugger == None: #i nitialize debugger\n","                    self.debugger = debugger(\"Control\",[\"K\",\"attempts\"],[10,50])\n","\n","                self.debugger.update_variables() # Get updated variables\n","                k,attempts= self.debugger.debug_vars[0:2]\n","                if k==0:\n","                    k = 2\n","                if attempts<10:\n","                    attempts = 10\n","            else:\n","                k = 2; attempts = 10\n","            segmented = self.segment_kmeans(img,k,attempts)\n","        else:\n","            print(f\"Unknown Method: {method}\")\n","\n","        return segmented"],"metadata":{"id":"k975zqzTc0V_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def main()"],"metadata":{"id":"cYVgzkP8c8JZ"}},{"cell_type":"code","source":["def main():\n","\n","    print_h(\"[main]: Applying different type of Image filters to input and analyzing their effects.\")\n","\n","    img = cv2.imread(\"Data/boy_who_lived/vignette.jpg\",cv2.IMREAD_ANYDEPTH)\n","    print(\"img Shape (Input)\",img.shape)\n","    if ( (len(img.shape)==3) and (img.shape[2]==3) ):\n","        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    else:\n","        gray = img\n","\n","    images = []\n","    titles = []\n","    images.append(gray)\n","    titles.append(\"img\")\n","\n","    img_segmentor = segmentation()\n","\n","    # Task 1: Segmentation using Thresholding\n","    print_h(\"[Segmentation Using Thresholding]: Investigating the use cases of Simple to adaptive thresholding.\")\n","\n","    # Case: Where thresholding might be the obvious choice\n","    #   a) Binary\n","    img_seg_thresh = img_segmentor.segment(gray)\n","    images.append(img_seg_thresh)\n","    titles.append(\"Thresholding (Simple)\")\n","\n","\n","\n","    #   a-2) Otsu\n","    img_seg_thresh = img_segmentor.segment(gray,type ='otsu')\n","    images.append(img_seg_thresh)\n","    titles.append(\"Thresholding (Otsu)\")\n","\n","    #   b) Adaptive mean\n","    img_seg_thresh_adaptive = img_segmentor.segment(gray,type=\"adaptive-mean\")\n","    images.append(img_seg_thresh_adaptive)\n","    titles.append(\"Thresholding (adaptive-mean)\")\n","\n","\n","    #   b) Adaptive guassian\n","    img_seg_thresh_adaptive = img_segmentor.segment(gray,type=\"adaptive-guass\")\n","    images.append(img_seg_thresh_adaptive)\n","    titles.append(\"Thresholding (adaptive-guass)\")\n","\n","\n","\n","\n","    # Displaying image and threshold result\n","    montage = build_montages(images,None,None,titles,True,True)\n","    for img in montage:\n","        cv2.imshow(\"img\",img)\n","    cv2.waitKey(0)\n","    cv2.destroyWindow(\"img\")\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    # Task 2: Segmentation using Color\n","    print_h(\"[Segmentation Using Color]: Performing segmentation based on the selected color.\")\n","    messi_img = cv2.imread(\"Data\\messi5.jpg\")\n","\n","    while(1):\n","        images.clear()\n","        titles.clear()\n","        # Adding image to list of images in montage\n","        images.append(messi_img)\n","        titles.append(\"img (Messi)\")\n","\n","        # 2) Segmentation using color\n","        img_seg_color = img_segmentor.segment(messi_img,\"color\",tune=False)\n","        images.append(img_seg_color)\n","        titles.append(\"Segmented (color)\")\n","\n","\n","        # 3) Segmentation using edges\n","        img_seg_edges = img_segmentor.segment(messi_img,\"edges\",tune=True)\n","        images.append(img_seg_edges)\n","        titles.append(\"Segmented (edges)\")\n","\n","\n","        # Displaying image and threshold result\n","        montage = build_montages(images,None,None,titles,True,True)\n","        for img in montage:\n","            cv2.imshow(\"img\",img)\n","        k = cv2.waitKey(1)\n","        if k==27:\n","            break\n","    cv2.destroyAllWindows()\n","    img_segmentor.debugger = None\n","\n","\n","\n","\n","    # Task 3: Segmentation using Clustering (kmeans)\n","    print_h(\"[Segmentation Using Clustering]: Applying kmeans to divide image into similar regions(clusters).\")\n","    baboon_img = cv2.imread(\"Data/baboon.jpg\")\n","\n","    while(1):\n","        images.clear()\n","        titles.clear()\n","        images.append(baboon_img)\n","        titles.append(\"img (baboon)\")\n","\n","        # Performing kmean segmentation\n","\n","        img_seg_kmeans = img_segmentor.segment(baboon_img,\"kmeans\",tune=True)\n","        images.append(img_seg_kmeans)\n","        titles.append(\"Segmented (kmeans)\")\n","\n","\n","\n","\n","\n","\n","\n","\n","        # Displaying image and threshold result\n","        montage = build_montages(images,None,None,titles,True,True)\n","        for img in montage:\n","            cv2.imshow(\"img\",img)\n","\n","        k = cv2.waitKey(1)\n","        if k==27:\n","            break"],"metadata":{"id":"Gln3yYhOdAP6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conditional Execution of Functions Based on Readiness Status"],"metadata":{"id":"Ec-kqvgBdM3S"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    i_am_ready = False\n","\n","    if i_am_ready:\n","        assignment()\n","    else:\n","        main()"],"metadata":{"id":"9iSQ5psUdORq"},"execution_count":null,"outputs":[]}]}