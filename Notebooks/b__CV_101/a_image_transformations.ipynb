{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZoQ/l2CmlS7jFz6Pa6zKa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"TLEA8HQsXmZj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_GpXM78sXWp8"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","from src.utilities import draw_points,print_h,build_montages,imshow\n","from loguru import logger"]},{"cell_type":"markdown","source":["### def get_bookcover(book_in_scne,debug = False)"],"metadata":{"id":"ZjCtg3XmXwc9"}},{"cell_type":"code","source":["def get_bookcover(book_in_scne,debug = False):\n","\n","    bookcover = book_in_scne.copy()\n","\n","    # Hint : Use setmousecallBack() to retrieve points neccesary for computing the transformation matrix\n","    # Type code here\n","\n","\n","    return bookcover"],"metadata":{"id":"GjZR5tloX2QR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def assignment(debug=True)"],"metadata":{"id":"-X7pE6wTX5K9"}},{"cell_type":"code","source":["def assignment(debug=True):\n","    if debug:\n","        print_h(\"[Assignment]: Use transformations and previous knowledge to recover only the book front (no background)\\n\")\n","    # Assignment : Use transformations and previous knowledge to recover only the book front (no background)\n","    #\n","    # Returns    : (img) Only the bookcover and nothing else.\n","    #\n","    # Hint       : If something has been distorted, By estimating the amount of distortion and using them\n","    #                                               Its effect can be easily reversed.\n","    #              Reference: https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87\n","    #                                     =======================================\n","    #              You can use the mouseevents to get points in the image that you are interested in\n","    #\n","\n","    #Input\n","    book_img = cv2.imread(\"Data/book_perspective.jpg\")\n","    if debug:\n","        imshow(\"book on table\",book_img)\n","        cv2.waitKey(0)\n","        cv2.destroyWindow(\"book on table\")\n","\n","    # Task Function\n","    bookcover = get_bookcover(book_img,debug)\n","\n","\n","    if np.array_equal(book_img,bookcover):\n","        logger.error(\"get_bookcover() needs to be coded to get the required(book cover) result.\\n\")\n","        exit(0)\n","\n","\n","    # Output (Display)\n","    if debug:\n","        imshow(\"bookcover\",bookcover)\n","        cv2.waitKey(0)\n","\n","    return bookcover"],"metadata":{"id":"ozk73V73X98C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def main()"],"metadata":{"id":"9mgHPgs9YD3G"}},{"cell_type":"code","source":["def main():\n","\n","    print_h(\"[main]: Perform different image transformation on an simple rectangle and analyze the resultant image.\")\n","\n","    images = []\n","    titles = []\n","\n","    # Perform Image transformations, Given an interesting assignment to utilize transformations\n","    img = np.zeros((200,300),np.uint8)\n","    rows,cols = img.shape[0:2]\n","    img[80:120,140:160] = 255\n","\n","    # Adding image to list of images for displaying as a montage\n","    images.append(img)\n","    titles.append(\"Orig\")\n","\n","    # 1) Resizing :\n","    width = 150\n","    height = 100\n","    new_size = (width,height)\n","    img_resized = cv2.resize(img,new_size)\n","    images.append(img_resized)\n","    titles.append(f\"Resized {new_size}\")\n","\n","\n","\n","    # 2) Translation :\n","    tx = 100\n","    ty = 50\n","    M = np.float32([[1,0,tx],[0,1,ty]])\n","    img_translated = cv2.warpAffine(img,M,(cols,rows))\n","    images.append(img_translated)\n","    titles.append(f\"translated (tx,ty)=({tx},{ty})\")\n","\n","\n","    # 3) Rotation :\n","    angle = 90\n","    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n","    img_rotated = cv2.warpAffine(img,M,(cols,rows))\n","    images.append(img_rotated)\n","    titles.append(f\"rotated {angle} deg\")\n","\n","\n","    # 4) Affine :\n","    cnts = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[0]\n","    cnt = cnts[0].reshape(4,2)\n","\n","    pts1 = np.float32([cnt[0],cnt[1],cnt[2]])\n","    pts2 = np.float32([[100,67],[100,134],[200,134]])\n","    M = cv2.getAffineTransform(pts1,pts2)\n","    img_affine = cv2.warpAffine(img,M,(cols,rows))\n","    img_affine = draw_points(img_affine,cnt[0:3])\n","    img_affine = draw_points(img_affine,pts2)\n","    images.append(img_affine)\n","    titles.append(\"affine\")\n","\n","    # 5) Perspective :\n","    pts1 = np.float32([cnt[0],cnt[1],cnt[2],cnt[3]]) # Anti-Clockwise\n","    pts2 = np.float32([[100,67],[120,134],[170,134],[200,67]])\n","\n","    M = cv2.getPerspectiveTransform(pts1,pts2)\n","    img_perspective = cv2.warpPerspective(img,M,(cols,rows))\n","    img_perspective = draw_points(img_perspective,cnt)\n","    img_perspective = draw_points(img_perspective,pts2)\n","    # Adding image to list of images for displaying as a montage\n","    images.append(img_perspective)\n","    titles.append(\"perspective\")\n","\n","    im_shape = (300,200)\n","    montages = build_montages(images, im_shape, None,titles,False,True)\n","    for img in montages:\n","        cv2.imshow(\"image\",img) # Show large image\n","    cv2.waitKey(0)"],"metadata":{"id":"0p8CLJdsYHzO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conditional Execution of Functions Based on Readiness Status"],"metadata":{"id":"dsOUCg90YLgH"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    i_am_ready = False\n","\n","    if i_am_ready:\n","        assignment()\n","    else:\n","        main()"],"metadata":{"id":"cAkBxKOyYRFm"},"execution_count":null,"outputs":[]}]}