{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPpO2ByTnp249ozYC2xwsUl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"Y66-Nj3lY8EF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahgMtplpY29q"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","from src.utilities import imshow,build_montages,print_h"]},{"cell_type":"markdown","source":["### def highlight_roi(image,debug = True)"],"metadata":{"id":"womEVHurZDnN"}},{"cell_type":"code","source":["def highlight_roi(image,debug = True):\n","    # Hint: Enhancing meteor edges could be the key but there is alot of noise so some smoothing is required\n","\n","    img_roi_highlighted = image.copy()\n","\n","    return img_roi_highlighted"],"metadata":{"id":"jp4siVO4ZHe1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def assignment(debug = True)"],"metadata":{"id":"SGyJssb7ZJ2Q"}},{"cell_type":"code","source":["def assignment(debug = True):\n","    if debug:\n","        print_h(\"[Assignment]: Highlight falling meteor in the scene\\n\")\n","    # Assignment: Define the algorithm whos goal is to highlight meteor (roi) in the whole scene\n","    #\n","    #\n","    # Hint: Along with using filter to silence the noise, Look into Unsharp Masking for highlighting\n","    #       Reference: https://scikit-image.org/docs/stable/auto_examples/filters/plot_unsharp_mask.html\n","    #\n","    #\n","    # Output: Video with > Roi-highlighted < saved to disk\n","    #\n","\n","    vid = cv2.VideoCapture(\"Data\\meteor_mini.mp4\")\n","\n","    # Extracting input video properties to be used for output videowriter initialization\n","    inp_fps = vid.get(cv2.CAP_PROP_FPS)\n","    width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n","    height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","    size = (int(width),int(height))\n","\n","    vid_roi_highlighted = cv2.VideoWriter(\"src/b__CV_101/vid_roi_highlighted.avi\",cv2.VideoWriter_fourcc(*'MJPG'),inp_fps,size)\n","\n","    while(vid.isOpened()):\n","        ret,frame = vid.read()\n","        if ret:\n","            if debug:\n","                imshow(\"Meteor_strike (Orig)\",frame)\n","            # ### Task Function ###\n","            roi_highlighted = highlight_roi(frame,debug)\n","            # Writing video to disk\n","            vid_roi_highlighted.write(roi_highlighted)\n","            # Output (Display)\n","            if debug:\n","                imshow(\"[2] Meteor strike\",roi_highlighted)\n","            k=cv2.waitKey(1)\n","            if k==27:\n","                break\n","        else:\n","            print(\"Video Ended\")\n","            break\n","\n","    vid_roi_highlighted.release()"],"metadata":{"id":"qkDx7eYvZU5h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Kernel and Image Configuration for Image Processing"],"metadata":{"id":"NcwcK6TJZuz9"}},{"cell_type":"code","source":["k_w = 3\n","k_h = 3\n","\n","\n","ksize = 3\n","\n","image_no = 0"],"metadata":{"id":"kzNw7THoZyO_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Interactive Functions for Image Processing Configuration and Denoising"],"metadata":{"id":"L2441s76Z00N"}},{"cell_type":"code","source":["def on_k_w_Change(val):\n","    global k_w\n","    k_w = 2*val + 1\n","\n","    if (k_w<3):\n","        k_w = 3\n","\n","def on_k_h_Change(val):\n","    global k_h\n","    k_h = 2*val + 1\n","\n","    if (k_h<3):\n","        k_h = 3\n","\n","def onksizeChange(val):\n","    global ksize\n","    ksize = 2*val + 1\n","\n","    if (ksize<3):\n","        ksize = 3\n","\n","def on_image_no_Change(val):\n","    global image_no\n","    image_no = val\n","\n","def denoising(noisy_img):\n","    images = []\n","    titles = []\n","\n","    images.append(noisy_img)\n","    titles.append(\"noisy_img\")"],"metadata":{"id":"lvSbOMWsaKO9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["a) LPF # 1: Box filter (Linear filter Used for smoothing, edge preservation minimal)"],"metadata":{"id":"GfirnuKgaOsY"}},{"cell_type":"code","source":[" #   a) LPF # 1: Box filter (Linear filter Used for smoothing, edge preservation minimal)\n","    kernel = np.ones((5,5),np.float32)/25 # box filter\n","    img_filtered = cv2.filter2D(noisy_img,-1,kernel) # depth = -1 (As input depth)\n","    images.append(img_filtered)\n","    titles.append(\"filtered (box)\")"],"metadata":{"id":"3PYClpBVaVVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["   b) LPF #2: Guassian filter (Linear filter Used for smoothing or to reduce noise , edge preservation okay)"],"metadata":{"id":"Bssn2wTbaYQ6"}},{"cell_type":"code","source":["#   b) LPF #2: Guassian filter (Linear filter Used for smoothing or to reduce noise , edge preservation okay)\n","    #                               Gives more weightage to closer pixels then farther in deciding result\n","    img_guass = cv2.GaussianBlur(noisy_img,(k_w,k_h),0,0)\n","    images.append(img_guass)\n","    titles.append(f\"filtered (guass {(k_w,k_h)} )\")"],"metadata":{"id":"5QNoGk6UafDV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["b) LPF #3: Median filter (Non-linear filter used for denoising (Salt-pepper noise), edge preservation better)"],"metadata":{"id":"JEhwb4s4ak3R"}},{"cell_type":"code","source":["#   b) LPF #3: Median filter (Non-linear filter used for denoising (Salt-pepper noise), edge preservation better)\n","    #                             Slow, because it needs to perform sorting to find the median in the underlying array\n","    img_median = cv2.medianBlur(noisy_img,ksize)\n","    images.append(img_median)\n","    titles.append(f\"filtered (median {ksize})\")"],"metadata":{"id":"uRI7h9vGauuv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["c) Combo #A Median -< Guassian"],"metadata":{"id":"Or9TMt91ayVq"}},{"cell_type":"code","source":["#   c) Combo #A Median -< Guassian\n","    img_medguass = cv2.GaussianBlur(img_median,(k_w,k_h),0,0)\n","    images.append(img_medguass)\n","    titles.append(f\"filtered (medguass)\")"],"metadata":{"id":"177GmbOka13q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Otsu Thresholding for segmenting ROI from the given image"],"metadata":{"id":"q_6j3oTRa6wi"}},{"cell_type":"code","source":["# Otsu Thresholding for segmenting ROI from the given image\n","    threshold_img = cv2.threshold(images[image_no],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n","\n","    images.append(threshold_img)\n","    titles.append(f\"threshed {titles[image_no]}\")"],"metadata":{"id":"yg1Ung1ca-CX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Displaying the montage"],"metadata":{"id":"9_GqcqJNbCDd"}},{"cell_type":"code","source":["# Displaying the montage\n","    montage_shape = (300,200)\n","    montage = build_montages(images,montage_shape,None,titles,True,True)\n","    for img in montage:\n","        imshow(\"Blurring (Noise Removal)\",img)"],"metadata":{"id":"AoA5_efEbFAK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def detect_edges(image)"],"metadata":{"id":"icBSW4sdbI2C"}},{"cell_type":"code","source":["def detect_edges(image):\n","    images = []\n","    titles = []\n","\n","    images.append(image)\n","    titles.append(\"image (Original)\")\n","\n","    edge_X = cv2.Sobel(image,-1,1,0)\n","    images.append(edge_X)\n","    titles.append(\"edges (X)\")\n","\n","    edge_X_64f = cv2.Sobel(image,cv2.CV_64F,1,0)\n","    edge_X_char = cv2.convertScaleAbs(edge_X_64f,alpha=(255/edge_X_64f.max()))\n","    images.append(edge_X_char)\n","    titles.append(\"edge_X (Scaleabs)\")\n","\n","    edge_Y = cv2.Sobel(image,-1,0,1)\n","    images.append(edge_Y)\n","    titles.append(\"edges (Y)\")\n","\n","    edge_Y_64f = cv2.Sobel(image,cv2.CV_64F,0,1)\n","    edge_Y_char = cv2.convertScaleAbs(edge_Y_64f, alpha=(255/edge_Y_64f.max()))\n","\n","    images.append(edge_Y_char)\n","    titles.append(\"edge_Y (Scaleabs)\")\n","\n","    edge_XY = cv2.Sobel(image,cv2.CV_64F,1,1)\n","    edge_XY = cv2.convertScaleAbs(edge_XY, alpha=(255/edge_XY.max()))\n","    images.append(edge_XY)\n","    titles.append(\"edges (XY)\")\n","\n","    edges_laplace = cv2.Laplacian(image,cv2.CV_64F,3)\n","    edges_laplace = cv2.convertScaleAbs(edges_laplace, alpha=(255/edges_laplace.max()))\n","    images.append(edges_laplace)\n","    titles.append(\"edges (Laplacian)\")\n","\n","    edges_canny = cv2.Canny(image,50,150,None,3)\n","    images.append(edges_canny)\n","    titles.append(\"edges (Canny)\")\n","\n","    montage_shape = (300,200)\n","    montage = build_montages(images,montage_shape,None,titles,True,True)\n","    for img in montage:\n","        imshow(\"Edge detection\",img)"],"metadata":{"id":"dZvPuCLRbM0o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### def main()"],"metadata":{"id":"E1HH77i3bTmM"}},{"cell_type":"code","source":["def main():\n","    print_h(\"[main]: Applying different type of Image filters to input and analyzing their effects.\")\n","    images = []\n","    titles = []\n","\n","    # Task 1: Smoothing using filter2d (box filter)\n","    img = cv2.imread(\"Data\\HappyFish.jpg\")\n","    images.append(img)\n","    titles.append(\"img (Orig)\")\n","\n","    # > Creating a box filter of size 5x5\n","    kernel = np.ones((5,5),np.float32)/25\n","    print(\"kernel = \",kernel)\n","    img_filtered = cv2.filter2D(img,-1,kernel)\n","    images.append(img_filtered)\n","    titles.append(\"filtered (box)\")\n","\n","\n","\n","    montage = build_montages(images,None,None,titles,True,True)\n","    for img in montage:\n","        imshow(\"Image Filtering\",img)\n","    cv2.waitKey(0)\n","    cv2.destroyAllWindows()\n","\n","\n","\n","    # Task 2: Noise Removal using low pass filters (Choise of filter depends on the noise characteristics)\n","    print_h(\"[Noise Removal]: Utilizing low-pass filters for noise removal in the given image.\")\n","    noisy_img = cv2.imread(\"Data/noisy2.png\",cv2.IMREAD_ANYDEPTH) # AnyDepth to ensure it is read as a grayscale\n","\n","\n","    cv2.namedWindow(\"Noise Removal\",cv2.WINDOW_NORMAL)\n","    cv2.createTrackbar(\"k_w\",\"Noise Removal\",k_w,30,on_k_w_Change)\n","    cv2.createTrackbar(\"k_h\",\"Noise Removal\",k_h,30,on_k_h_Change)\n","    cv2.createTrackbar(\"ksize\",\"Noise Removal\",ksize,30,onksizeChange)\n","    cv2.createTrackbar(\"image_no\",\"Noise Removal\",image_no,4,on_image_no_Change)\n","\n","\n","    while(1):\n","        denoising(noisy_img)\n","        k = cv2.waitKey(1)\n","        if k==27:\n","            break\n","\n","\n","\n","    # Task 3: Edge detection using high pass filters (Choise of filter depends on the type of edge we want)\n","    print_h(\"[Edge detection]: Leveraging high-pass filters to extract areas of change in image.\")\n","    shapes_img = cv2.imread(\"Data\\shapes.PNG\",cv2.IMREAD_ANYDEPTH) # AnyDepth to ensure it is read as a grayscale\n","\n","\n","    detect_edges(shapes_img)\n","    cv2.waitKey(0)"],"metadata":{"id":"TGJvLTADbZCR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conditional Execution of Functions Based on Readiness Status"],"metadata":{"id":"sY5YzCHPbfFC"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    i_am_ready = False\n","\n","    if i_am_ready:\n","        assignment()\n","    else:\n","        main()"],"metadata":{"id":"nQAvbf2Tbm-e"},"execution_count":null,"outputs":[]}]}